{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMa Index \n",
    "\n",
    "### Introduction\n",
    "\n",
    "A framework for LLM applications to **inject, structure,** and **access private domain-specific data**\n",
    "\n",
    "**Why LlamaIndex is needed**\n",
    "\n",
    "- LLM is basically trained on a large amount of public data.\n",
    "- Applications built on top of large language models often need to be augmented with private or domain-specific data\n",
    "- These data exist in various places, and LlamaIndex builds a bridge for us to connect the two.\n",
    "\n",
    "![image](https://github.com/xinyun2000/Skills/assets/130521370/a2dc64e5-7f68-4de3-83e9-72db9afa125f)\n",
    "\n",
    "LlamaIndex works with various LLMs\n",
    "\n",
    "![1696995018018](https://github.com/xinyun2000/Skills/assets/130521370/872c4726-c1ec-442d-9920-d515af7c70a8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction code: query information from txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex,SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author of the given context is Paul Graham.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Who is the author?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is an individual mentioned in the given context. Based on the information provided, he is a programmer and writer who has worked on various projects, including an interpreter called Bel. He has also written essays and has had experience with starting companies, such as Viaweb, which was an application service provider. Additionally, he has worked on a new dialect of Lisp called Arc.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Introduce me Paul Graham\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
